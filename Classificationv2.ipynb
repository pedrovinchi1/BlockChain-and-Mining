{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONXIDv1f9ZEQ4u7+3Morwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrovinchi1/BlockChain-and-Mining/blob/main/Classificationv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iMt4hIa4Mq56"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "7_f9G_YTM4Wc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "SKy1unwNNBnn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "E9SKaYvpNDlc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mGgi9_wNFQQ",
        "outputId": "3aec7c5f-017f-4a57-bf59-9068162d9b99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/puneet6060/intel-image-classification\n",
            "License(s): copyright-authors\n",
            "Downloading intel-image-classification.zip to /content\n",
            " 94% 325M/346M [00:01<00:00, 234MB/s]\n",
            "100% 346M/346M [00:01<00:00, 201MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q intel-image-classification.zip -d intel-image-classification"
      ],
      "metadata": {
        "id": "X_PHlY68NHrI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "# === CONFIGURAÇÕES GLOBAIS ===\n",
        "caminho_dataset = './intel-image-classification'\n",
        "caminho_treino = os.path.join(caminho_dataset, 'seg_train/seg_train')\n",
        "caminho_validacao = os.path.join(caminho_dataset, 'seg_test/seg_test')\n",
        "forma_img = (224, 224, 3)\n",
        "tam_lote = 32\n",
        "num_epocas_finetuning = 10\n",
        "\n",
        "# === FUNÇÕES AUXILIARES ===\n",
        "# Função para carregar imagens de treino\n",
        "def obter_imagens_treino(caminho_imagens_treino, forma_img, tam_lote):\n",
        "    gerador_imagens = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    imagens_treino = gerador_imagens.flow_from_directory(\n",
        "        caminho_imagens_treino,\n",
        "        target_size=forma_img[:2],\n",
        "        batch_size=tam_lote,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "    return imagens_treino\n",
        "\n",
        "# Função para carregar imagens de validação\n",
        "def obter_imagens_validacao(caminho_imagens_validacao, forma_img, tam_lote):\n",
        "    gerador_imagens = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    imagens_validacao = gerador_imagens.flow_from_directory(\n",
        "        caminho_imagens_validacao,\n",
        "        target_size=forma_img[:2],\n",
        "        batch_size=tam_lote,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    return imagens_validacao\n",
        "\n",
        "# Função para criar o modelo InceptionV3\n",
        "def obter_modelo_inception(num_classes):\n",
        "    modelo_base = keras.applications.InceptionV3(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    modelo_base.trainable = False\n",
        "    # Adiciona camadas personalizadas\n",
        "    inputs = keras.Input(shape=(224, 224, 3))\n",
        "    x = modelo_base(inputs, training=False)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    modelo = keras.Model(inputs, outputs)\n",
        "    modelo.summary()\n",
        "    return modelo\n",
        "\n",
        "# Função para compilar o modelo\n",
        "def compilar_modelo(modelo, learning_rate=0.0001):\n",
        "    otimizador = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    modelo.compile(optimizer=otimizador, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return modelo\n",
        "\n",
        "# Função para treinar o modelo\n",
        "def treinar_modelo(modelo, imagens_treino, imagens_validacao, num_epocas):\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath='melhores_pesos.keras',\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max'\n",
        "    )\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    historico = modelo.fit(\n",
        "        imagens_treino,\n",
        "        epochs=num_epocas,\n",
        "        validation_data=imagens_validacao,\n",
        "        callbacks=[checkpoint_callback, early_stop]\n",
        "    )\n",
        "    return historico\n",
        "\n",
        "# Função para avaliar o modelo\n",
        "def avaliar_modelo(modelo, imagens_validacao):\n",
        "\n",
        "    # Previsões\n",
        "    previsoes = modelo.predict(imagens_validacao)\n",
        "    previsoes_classes = np.argmax(previsoes, axis=1)\n",
        "    verdadeiras_classes = imagens_validacao.classes\n",
        "    nomes_classes = list(imagens_validacao.class_indices.keys())\n",
        "\n",
        "    # Matriz de confusão\n",
        "    matriz_confusao = confusion_matrix(verdadeiras_classes, previsoes_classes)\n",
        "    print(\"Matriz de Confusão:\")\n",
        "    print(matriz_confusao)\n",
        "\n",
        "    # Relatório de classificação\n",
        "    relatorio_classificacao = classification_report(verdadeiras_classes, previsoes_classes, target_names=nomes_classes)\n",
        "    print(\"Relatório de Classificação:\")\n",
        "    print(relatorio_classificacao)\n",
        "\n",
        "    # Acurácia\n",
        "    acuracia = accuracy_score(verdadeiras_classes, previsoes_classes)\n",
        "    print(f\"Acurácia: {acuracia:.4f}\")\n",
        "    # Plotar matriz de confusão\n",
        "\n",
        "    plot_matriz_confusao(matriz_confusao, nomes_classes)\n",
        "\n",
        "# Função para plotar a matriz de confusão\n",
        "def plot_matriz_confusao(matriz_confusao, nomes_classes):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(matriz_confusao, interpolation='nearest', cmap='Blues')\n",
        "    plt.title('Matriz de Confusão')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(nomes_classes))\n",
        "    plt.xticks(tick_marks, nomes_classes, rotation=45)\n",
        "    plt.yticks(tick_marks, nomes_classes)\n",
        "    fmt = 'd'\n",
        "    thresh = matriz_confusao.max() / 2.\n",
        "    for i, j in itertools.product(range(matriz_confusao.shape[0]), range(matriz_confusao.shape[1])):\n",
        "        plt.text(j, i, format(matriz_confusao[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matriz_confusao[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('Verdadeiro')\n",
        "    plt.xlabel('Previsto')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Função para plotar o histórico de treinamento\n",
        "def plot_historico(historico):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Gráfico de acurácia\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(historico.history['accuracy'], label='Treino')\n",
        "    plt.plot(historico.history['val_accuracy'], label='Validação')\n",
        "    plt.title('Acurácia')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Acurácia')\n",
        "    plt.legend()\n",
        "\n",
        "    # Gráfico de perda\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(historico.history['loss'], label='Treino')\n",
        "    plt.plot(historico.history['val_loss'], label='Validação')\n",
        "    plt.title('Perda')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Função para realizar o fine-tuning do modelo\n",
        "def fine_tuning_modelo(modelo, imagens_treino, imagens_validacao):\n",
        "    # Descongelar algumas camadas do modelo base\n",
        "    for layer in modelo.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "    # Recompilar o modelo com uma taxa de aprendizado menor\n",
        "    otimizador_finetuning = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    modelo.compile(optimizer=otimizador_finetuning, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Definir callbacks\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath='melhores_pesos_finetuning.keras',\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max'\n",
        "    )\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    # Continuar o treinamento\n",
        "    historico_finetuning = modelo.fit(\n",
        "        imagens_treino,\n",
        "        epochs=num_epocas_finetuning,  # Menos épocas para fine-tuning\n",
        "        validation_data=imagens_validacao,\n",
        "        callbacks=[checkpoint_callback, early_stop]\n",
        "    )\n",
        "    return historico_finetuning\n",
        "\n",
        "# === PIPELINE PRINCIPAL ===\n",
        "# Carregamento de dados\n",
        "imagens_treino = obter_imagens_treino(caminho_treino, forma_img, tam_lote)\n",
        "imagens_validacao = obter_imagens_validacao(caminho_validacao, forma_img, tam_lote)\n",
        "\n",
        "# Criação e compilação do modelo\n",
        "modelo = obter_modelo_inception(imagens_treino.num_classes)\n",
        "modelo = compilar_modelo(modelo)\n",
        "\n",
        "# Fine-tuning do modelo\n",
        "historico_finetuning = fine_tuning_modelo(modelo, imagens_treino, imagens_validacao)\n",
        "\n",
        "# Plotar gráficos do fine-tuning\n",
        "plot_historico(historico_finetuning)\n",
        "\n",
        "# Avaliar o modelo após o fine-tuning\n",
        "avaliar_modelo(modelo, imagens_validacao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "e1b77n3cNJEi",
        "outputId": "bc335df4-8844-4494-d7f7-fd068ec60c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m21,802,784\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │          \u001b[38;5;34m12,294\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,815,078\u001b[0m (83.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,815,078</span> (83.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,294\u001b[0m (48.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,294</span> (48.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,802,784\u001b[0m (83.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7586s\u001b[0m 17s/step - accuracy: 0.4810 - loss: 1.3007 - val_accuracy: 0.8913 - val_loss: 0.3412\n",
            "Epoch 2/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7498s\u001b[0m 17s/step - accuracy: 0.8434 - loss: 0.4519 - val_accuracy: 0.9103 - val_loss: 0.2472\n",
            "Epoch 3/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7453s\u001b[0m 17s/step - accuracy: 0.8702 - loss: 0.3689 - val_accuracy: 0.9177 - val_loss: 0.2225\n",
            "Epoch 4/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7479s\u001b[0m 17s/step - accuracy: 0.8934 - loss: 0.2990 - val_accuracy: 0.9267 - val_loss: 0.2074\n",
            "Epoch 5/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7516s\u001b[0m 17s/step - accuracy: 0.8953 - loss: 0.2890 - val_accuracy: 0.9283 - val_loss: 0.1990\n",
            "Epoch 6/10\n",
            "\u001b[1m334/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28:30\u001b[0m 16s/step - accuracy: 0.9058 - loss: 0.2582"
          ]
        }
      ]
    }
  ]
}